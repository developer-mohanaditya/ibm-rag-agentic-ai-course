{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f484f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ibm_rag_agentic_ai_course\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for the YouTube bot\n",
    "import gradio as gr\n",
    "import re  #For extracting video id \n",
    "from youtube_transcript_api import YouTubeTranscriptApi  # For extracting transcripts from YouTube videos\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # For splitting text into manageable segments\n",
    "\n",
    "# from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes  # For specifying model types\n",
    "# from ibm_watsonx_ai import APIClient, Credentials  # For API client and credentials management\n",
    "# from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams  # For managing model parameters\n",
    "# from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods  # For defining decoding methods\n",
    "# from langchain_ibm import WatsonxLLM, WatsonxEmbeddings  # For interacting with IBM's LLM and embeddings\n",
    "# from ibm_watsonx_ai.foundation_models.utils import get_embedding_model_specs  # For retrieving model specifications\n",
    "# from ibm_watsonx_ai.foundation_models.utils.enums import EmbeddingTypes  # For specifying types of embeddings\n",
    "\n",
    "\n",
    "from langchain_community.vectorstores import FAISS  # For efficient vector storage and similarity search\n",
    "from langchain.chains import LLMChain  # For creating chains of operations with LLMs\n",
    "from langchain.prompts import PromptTemplate  # For defining prompt templates\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Suppress warnings for cleaner output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda5a42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM connection successful: Yes, I can. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LLM Setup using OpenRouter\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Load API key from .env\n",
    "load_dotenv()\n",
    "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "if not openrouter_api_key:\n",
    "    raise ValueError(\"OPENROUTER_API_KEY not found in environment variables\")\n",
    "\n",
    "# Initialize LLM via OpenRouter\n",
    "llm = ChatOpenAI(\n",
    "    model=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
    "    api_key=openrouter_api_key,\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "# Test LLM connection\n",
    "try:\n",
    "    response = llm.invoke(\"Hello, can you respond?\")\n",
    "    print(\"LLM connection successful:\", response.content)\n",
    "except Exception as e:\n",
    "    print(\"LLM connection failed:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e18cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Youtube video ID from URL\n",
    "def get_video_id(url):    \n",
    "    # Regex pattern to match YouTube video URLs\n",
    "    pattern = r'https:\\/\\/www\\.youtube\\.com\\/watch\\?v=([a-zA-Z0-9_-]{11})'\n",
    "    match = re.search(pattern, url)\n",
    "    return match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3481a41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dQw4w9WgXcQ\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"\n",
    "video_id = get_video_id(url)\n",
    "print(video_id)  # Output: dQw4w9WgXcQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a68c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube Transcript API to get transcript\n",
    "\n",
    "def get_transcript(url):\n",
    "    # Extracts the video ID from the URL\n",
    "    video_id = get_video_id(url)\n",
    "    \n",
    "    # Create a YouTubeTranscriptApi() object\n",
    "    ytt_api = YouTubeTranscriptApi()\n",
    "    \n",
    "    # Fetch the list of available transcripts for the given YouTube video\n",
    "    transcripts = ytt_api.list(video_id)\n",
    "    \n",
    "    transcript = \"\"\n",
    "    for t in transcripts:\n",
    "        # Check if the transcript's language is English\n",
    "        if t.language_code == 'en':\n",
    "            if t.is_generated:\n",
    "                # If no transcript has been set yet, use the auto-generated one\n",
    "                if len(transcript) == 0:\n",
    "                    transcript = t.fetch()\n",
    "            else:\n",
    "                # If a manually created transcript is found, use it (overrides auto-generated)\n",
    "                transcript = t.fetch()\n",
    "                break  # Prioritize the manually created transcript, exit the loop\n",
    "    \n",
    "    return transcript if transcript else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "963ed8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FetchedTranscript(snippets=[FetchedTranscriptSnippet(text='[♪♪♪]', start=1.36, duration=1.68), FetchedTranscriptSnippet(text=\"♪ We're no strangers to love ♪\", start=18.64, duration=3.24), FetchedTranscriptSnippet(text='♪ You know the rules\\nand so do I ♪', start=22.64, duration=4.32), FetchedTranscriptSnippet(text=\"♪ A full commitment's\\nwhat I'm thinking of ♪\", start=27.04, duration=4.0), FetchedTranscriptSnippet(text=\"♪ You wouldn't get this\\nfrom any other guy ♪\", start=31.12, duration=3.96), FetchedTranscriptSnippet(text=\"♪ I just wanna tell you\\nhow I'm feeling ♪\", start=35.16, duration=4.36), FetchedTranscriptSnippet(text='♪ Gotta make you understand ♪', start=40.52, duration=2.4), FetchedTranscriptSnippet(text='♪ Never gonna give you up ♪', start=43.0, duration=2.12), FetchedTranscriptSnippet(text='♪ Never gonna let you down ♪', start=45.2, duration=1.88), FetchedTranscriptSnippet(text='♪ Never gonna run around\\nand desert you ♪', start=47.32, duration=3.8), FetchedTranscriptSnippet(text='♪ Never gonna make you cry ♪', start=51.48, duration=2.0), FetchedTranscriptSnippet(text='♪ Never gonna say goodbye ♪', start=53.6, duration=1.92), FetchedTranscriptSnippet(text='♪ Never gonna tell a lie\\nand hurt you ♪', start=55.72, duration=3.64), FetchedTranscriptSnippet(text=\"♪ We've known each other\\nfor so long ♪\", start=60.8, duration=4.0), FetchedTranscriptSnippet(text=\"♪ Your heart's been aching\\nbut you're too shy to say it ♪\", start=64.88, duration=4.16), FetchedTranscriptSnippet(text=\"♪ Inside we both know\\nwhat's been going ♪\", start=69.12, duration=3.84), FetchedTranscriptSnippet(text=\"♪ We know the game\\nand we're gonna play it ♪\", start=73.36, duration=3.84), FetchedTranscriptSnippet(text=\"♪ And if you ask me\\nhow I'm feeling ♪\", start=77.4, duration=4.64), FetchedTranscriptSnippet(text=\"♪ Don't tell me\\nyou're too blind to see ♪\", start=82.4, duration=2.84), FetchedTranscriptSnippet(text='♪ Never gonna give you up ♪', start=85.32, duration=1.96), FetchedTranscriptSnippet(text='♪ Never gonna let you down ♪', start=87.36, duration=1.96), FetchedTranscriptSnippet(text='♪ Never gonna run around\\nand desert you ♪', start=89.44, duration=4.28), FetchedTranscriptSnippet(text='♪ Never gonna make you cry ♪', start=93.8, duration=1.8), FetchedTranscriptSnippet(text='♪ Never gonna say goodbye ♪', start=95.76, duration=2.24), FetchedTranscriptSnippet(text='♪ Never gonna tell a lie\\nand hurt you ♪', start=98.08, duration=3.96), FetchedTranscriptSnippet(text='♪ Never gonna give you up ♪', start=102.2, duration=1.92), FetchedTranscriptSnippet(text='♪ Never gonna let you down ♪', start=104.28, duration=2.08), FetchedTranscriptSnippet(text='♪ Never gonna run around\\nand desert you ♪', start=106.48, duration=3.6), FetchedTranscriptSnippet(text='♪ Never gonna make you cry ♪', start=110.76, duration=1.96), FetchedTranscriptSnippet(text='♪ Never gonna say goodbye ♪', start=112.8, duration=1.88), FetchedTranscriptSnippet(text='♪ Never gonna tell a lie\\nand hurt you ♪', start=114.96, duration=3.8), FetchedTranscriptSnippet(text='♪ (Ooh, give you up) ♪', start=119.84, duration=3.12), FetchedTranscriptSnippet(text='♪ (Ooh, give you up) ♪', start=123.72, duration=3.64), FetchedTranscriptSnippet(text='♪ Never gonna give,\\nnever gonna give ♪', start=128.48, duration=1.64), FetchedTranscriptSnippet(text='♪ (Give you up) ♪', start=130.24, duration=1.32), FetchedTranscriptSnippet(text='♪ Never gonna give,\\nnever gonna give ♪', start=132.48, duration=1.76), FetchedTranscriptSnippet(text='♪ (Give you up) ♪', start=134.36, duration=1.56), FetchedTranscriptSnippet(text=\"♪ We've known each other\\nfor so long ♪\", start=136.76, duration=4.32), FetchedTranscriptSnippet(text=\"♪ Your heart's been aching\\nbut you're too shy to say it ♪\", start=141.2, duration=4.0), FetchedTranscriptSnippet(text=\"♪ Inside we both know\\nwhat's been going ♪\", start=145.28, duration=3.84), FetchedTranscriptSnippet(text=\"♪ We know the game\\nand we're gonna play it ♪\", start=149.52, duration=3.68), FetchedTranscriptSnippet(text=\"♪ I just wanna tell you\\nhow I'm feeling ♪\", start=153.36, duration=4.68), FetchedTranscriptSnippet(text='♪ Gotta make you understand ♪', start=158.64, duration=2.68), FetchedTranscriptSnippet(text='♪ Never gonna give you up ♪', start=161.4, duration=1.96), FetchedTranscriptSnippet(text='♪ Never gonna let you down ♪', start=163.44, duration=2.2), FetchedTranscriptSnippet(text='♪ Never gonna run around\\nand desert you ♪', start=165.72, duration=4.0), FetchedTranscriptSnippet(text='♪ Never gonna make you cry ♪', start=169.8, duration=1.84), FetchedTranscriptSnippet(text='♪ Never gonna say goodbye ♪', start=171.8, duration=2.16), FetchedTranscriptSnippet(text='♪ Never gonna tell a lie\\nand hurt you ♪', start=174.04, duration=3.56), FetchedTranscriptSnippet(text='♪ Never gonna give you up ♪', start=178.2, duration=2.04), FetchedTranscriptSnippet(text='♪ Never gonna let you down ♪', start=180.32, duration=2.12), FetchedTranscriptSnippet(text='♪ Never gonna run around\\nand desert you ♪', start=182.52, duration=4.12), FetchedTranscriptSnippet(text='♪ Never gonna make you cry ♪', start=186.72, duration=2.0), FetchedTranscriptSnippet(text='♪ Never gonna say goodbye ♪', start=188.84, duration=1.88), FetchedTranscriptSnippet(text='♪ Never gonna tell a lie\\nand hurt you ♪', start=190.84, duration=4.36), FetchedTranscriptSnippet(text='♪ Never gonna give you up ♪', start=195.28, duration=1.84), FetchedTranscriptSnippet(text='♪ Never gonna let you down ♪', start=197.2, duration=2.04), FetchedTranscriptSnippet(text='♪ Never gonna run around\\nand desert you ♪', start=199.4, duration=3.72), FetchedTranscriptSnippet(text='♪ Never gonna make you cry ♪', start=203.36, duration=2.24), FetchedTranscriptSnippet(text='♪ Never gonna say goodbye ♪', start=205.68, duration=2.16), FetchedTranscriptSnippet(text='♪ Never gonna tell a lie\\nand hurt you ♪', start=207.92, duration=3.4)], video_id='dQw4w9WgXcQ', language='English', language_code='en', is_generated=False)\n"
     ]
    }
   ],
   "source": [
    "# Sample YouTube URL\n",
    "url = \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"\n",
    "\n",
    "# Fetching the transcript\n",
    "transcript = get_transcript(url)\n",
    "\n",
    "# Output the fetched transcript\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "666509a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the transcript into text segments\n",
    "\n",
    "def process(transcript):\n",
    "    # Initialize an empty string to hold the formatted transcript\n",
    "    txt = \"\"\n",
    "    \n",
    "    # Loop through each entry in the transcript\n",
    "    for i in transcript:\n",
    "        try:\n",
    "            # Append the text and its start time to the output string\n",
    "            txt += f\"Text: {i['text']} Start: {i['start']}\\n\"\n",
    "        except (KeyError, AttributeError):\n",
    "            # If there is an issue accessing 'text' or 'start', skip this entry\n",
    "            pass\n",
    "            \n",
    "    # Return the processed transcript as a single string\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b07e36b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: We're no strangers to love. Start: 0.0\n",
      "Text: You know the rules and so do I. Start: 3.5\n",
      "Text: A full commitment's what I'm thinking of. Start: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample transcript list\n",
    "transcript = [\n",
    "    {\n",
    "        \"text\": \"We're no strangers to love.\",\n",
    "        \"start\": 0.0,\n",
    "        \"duration\": 3.5\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"You know the rules and so do I.\",\n",
    "        \"start\": 3.5,\n",
    "        \"duration\": 4.0\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"A full commitment's what I'm thinking of.\",\n",
    "        \"start\": 7.5,\n",
    "        \"duration\": 4.0\n",
    "    }\n",
    "]\n",
    "\n",
    "# Processing the transcript\n",
    "formatted_transcript = process(transcript)\n",
    "\n",
    "# Output the processed transcript\n",
    "print(formatted_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc7b6a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking the transcript\n",
    "\n",
    "def chunk_transcript(processed_transcript, chunk_size=200, chunk_overlap=20):\n",
    "    # Initialize the RecursiveCharacterTextSplitter with specified chunk size and overlap\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "\n",
    "    # Split the transcript into chunks\n",
    "    chunks = text_splitter.split_text(processed_transcript)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba639441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Text: We're no strangers to love. Start: 0.0\\nText: You know the rules and so do I. Start: 3.5\\nText: A full commitment's what I'm thinking of. Start: 7.5\"]\n"
     ]
    }
   ],
   "source": [
    "# Sample processed transcript string\n",
    "processed_transcript = \"\"\"Text: We're no strangers to love. Start: 0.0\n",
    "Text: You know the rules and so do I. Start: 3.5\n",
    "Text: A full commitment's what I'm thinking of. Start: 7.5\"\"\"\n",
    "\n",
    "# Chunking the transcript\n",
    "chunks = chunk_transcript(processed_transcript)\n",
    "\n",
    "# Output the chunks\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b02eb600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding the chunks\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Embedding the chunks\n",
    "def create_faiss_index(chunks, embedding_model):\n",
    "    \"\"\"\n",
    "    Create a FAISS index from text chunks using the specified embedding model.\n",
    "    \n",
    "    :param chunks: List of text chunks\n",
    "    :param embedding_model: The embedding model to use\n",
    "    :return: FAISS index\n",
    "    \"\"\"\n",
    "    # Use the FAISS library to create an index from the provided text chunks\n",
    "    return FAISS.from_texts(chunks, embedding_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d649804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing similarity search\n",
    "\n",
    "def perform_similarity_search(faiss_index, query, k=3):\n",
    "    \"\"\"\n",
    "    Search for specific queries within the embedded transcript using the FAISS index.\n",
    "    \n",
    "    :param faiss_index: The FAISS index containing embedded text chunks\n",
    "    :param query: The text input for the similarity search\n",
    "    :param k: The number of similar results to return (default is 3)\n",
    "    :return: List of similar results\n",
    "    \"\"\"\n",
    "    # Perform the similarity search using the FAISS index\n",
    "    results = faiss_index.similarity_search(query, k=k)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "044c2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing the transcript\n",
    "\n",
    "# Define the prompt template\n",
    "\n",
    "def create_summary_prompt():\n",
    "    \"\"\"\n",
    "    Create a PromptTemplate for summarizing a YouTube video transcript.\n",
    "    \n",
    "    :return: PromptTemplate object\n",
    "    \"\"\"\n",
    "    # Define the template for the summary prompt\n",
    "    template = \"\"\"\n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "    You are an AI assistant tasked with summarizing YouTube video transcripts. Provide concise, informative summaries that capture the main points of the video content.\n",
    "\n",
    "    Instructions:\n",
    "    1. Summarize the transcript in a single concise paragraph.\n",
    "    2. Ignore any timestamps in your summary.\n",
    "    3. Focus on the spoken content (Text) of the video.\n",
    "\n",
    "    Note: In the transcript, \"Text\" refers to the spoken words in the video, and \"start\" indicates the timestamp when that part begins in the video.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Please summarize the following YouTube video transcript:\n",
    "\n",
    "    {transcript}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the PromptTemplate object with the defined template\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"transcript\"],\n",
    "        template=template\n",
    "    )\n",
    "    \n",
    "    return prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc449d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the LLM chain for summarization\n",
    "\n",
    "def create_summary_chain(llm, prompt, verbose=True):\n",
    "    \"\"\"\n",
    "    Create an LLMChain for generating summaries.\n",
    "    \n",
    "    :param llm: Language model instance\n",
    "    :param prompt: PromptTemplate instance\n",
    "    :param verbose: Boolean to enable verbose output (default: True)\n",
    "    :return: LLMChain instance\n",
    "    \"\"\"\n",
    "    return LLMChain(llm=llm, prompt=prompt, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "889dc4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving relevant context and generating answers\n",
    "\n",
    "## Define the retrieval function\n",
    "\n",
    "def retrieve(query, faiss_index, k=7):\n",
    "    \"\"\"\n",
    "    Retrieve relevant context from the FAISS index based on the user's query.\n",
    "\n",
    "    Parameters:\n",
    "        query (str): The user's query string.\n",
    "        faiss_index (FAISS): The FAISS index containing the embedded documents.\n",
    "        k (int, optional): The number of most relevant documents to retrieve (default is 3).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of the k most relevant documents (or document chunks).\n",
    "    \"\"\"\n",
    "    relevant_context = faiss_index.similarity_search(query, k=k)\n",
    "    return relevant_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75155d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Q&A prompt template\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "def create_qa_prompt_template():\n",
    "    \"\"\"\n",
    "    Create a PromptTemplate for question answering based on video content.\n",
    "\n",
    "    Returns:\n",
    "        PromptTemplate: A PromptTemplate object configured for Q&A tasks.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the template string\n",
    "    qa_template = \"\"\"\n",
    "    You are an expert assistant providing detailed answers based on the following video content.\n",
    "\n",
    "    Relevant Video Context: {context}\n",
    "\n",
    "    Based on the above context, please answer the following question:\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the PromptTemplate object\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=qa_template\n",
    "    )\n",
    "\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb707425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You are an expert assistant providing detailed answers based on the following video content.\n",
      "\n",
      "    Relevant Video Context: This video explains the fundamentals of quantum physics.\n",
      "\n",
      "    Based on the above context, please answer the following question:\n",
      "    Question: What are the key principles discussed in the video?\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Creating the Q&A prompt template \n",
    "qa_prompt_template = create_qa_prompt_template()\n",
    "\n",
    "# Example of how to use the prompt template with context and a question\n",
    "context = \"This video explains the fundamentals of quantum physics.\"\n",
    "question = \"What are the key principles discussed in the video?\"\n",
    "\n",
    "# Generating the prompt\n",
    "generated_prompt = qa_prompt_template.format(context=context, question=question)\n",
    "\n",
    "# Output the generated prompt\n",
    "print(generated_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "203a5575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the Q&A LLMChain\n",
    "\n",
    "def create_qa_chain(llm, prompt_template, verbose=True):\n",
    "    \"\"\"\n",
    "    Create an LLMChain for question answering.\n",
    "\n",
    "    Args:\n",
    "        llm: Language model instance\n",
    "            The language model to use in the chain (e.g., WatsonxGranite).\n",
    "        prompt_template: PromptTemplate\n",
    "            The prompt template to use for structuring inputs to the language model.\n",
    "        verbose: bool, optional (default=True)\n",
    "            Whether to enable verbose output for the chain.\n",
    "\n",
    "    Returns:\n",
    "        LLMChain: An instantiated LLMChain ready for question answering.\n",
    "    \"\"\"\n",
    "    \n",
    "    return LLMChain(llm=llm, prompt=prompt_template, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd9dbf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating an answer\n",
    "\n",
    "def generate_answer(question, faiss_index, qa_chain, k=7):\n",
    "    \"\"\"\n",
    "    Retrieve relevant context and generate an answer based on user input.\n",
    "\n",
    "    Args:\n",
    "        question: str\n",
    "            The user's question.\n",
    "        faiss_index: FAISS\n",
    "            The FAISS index containing the embedded documents.\n",
    "        qa_chain: LLMChain\n",
    "            The question-answering chain (LLMChain) to use for generating answers.\n",
    "        k: int, optional (default=3)\n",
    "            The number of relevant documents to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated answer to the user's question.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve relevant context\n",
    "    relevant_context = retrieve(question, faiss_index, k=k)\n",
    "\n",
    "    # Generate answer using the QA chain\n",
    "    answer = qa_chain.predict(context=relevant_context, question=question)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8b26ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Summarizing a video\n",
    "\n",
    "# Initialize an empty string to store the processed transcript after fetching and preprocessing\n",
    "processed_transcript = \"\"\n",
    "\n",
    "def summarize_video(video_url):\n",
    "    \"\"\"\n",
    "    Title: Summarize Video\n",
    "\n",
    "    Description:\n",
    "    This function generates a summary of the video using the preprocessed transcript.\n",
    "    If the transcript hasn't been fetched yet, it fetches it first.\n",
    "\n",
    "    Args:\n",
    "        video_url (str): The URL of the YouTube video from which the transcript is to be fetched.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated summary of the video or a message indicating that no transcript is available.\n",
    "    \"\"\"\n",
    "    global fetched_transcript, processed_transcript\n",
    "    \n",
    "    \n",
    "    if video_url:\n",
    "        # Fetch and preprocess transcript\n",
    "        fetched_transcript = get_transcript(video_url)\n",
    "        processed_transcript = process(fetched_transcript)\n",
    "    else:\n",
    "        return \"Please provide a valid YouTube URL.\"\n",
    "\n",
    "    if processed_transcript:\n",
    "        # Step 1: Set up IBM Watson credentials\n",
    "        model_id, credentials, client, project_id = setup_credentials()\n",
    "\n",
    "        # Step 2: Initialize WatsonX LLM for summarization\n",
    "        llm = initialize_watsonx_llm(model_id, credentials, project_id, define_parameters())\n",
    "\n",
    "        # Step 3: Create the summary prompt and chain\n",
    "        summary_prompt = create_summary_prompt()\n",
    "        summary_chain = create_summary_chain(llm, summary_prompt)\n",
    "\n",
    "        # Step 4: Generate the video summary\n",
    "        summary = summary_chain.run({\"transcript\": processed_transcript})\n",
    "        return summary\n",
    "    else:\n",
    "        return \"No transcript available. Please fetch the transcript first.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "466d8ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answering a user's question\n",
    "\n",
    "def answer_question(video_url, user_question):\n",
    "    \"\"\"\n",
    "    Title: Answer User's Question\n",
    "\n",
    "    Description:\n",
    "    This function retrieves relevant context from the FAISS index based on the user’s query \n",
    "    and generates an answer using the preprocessed transcript.\n",
    "    If the transcript hasn't been fetched yet, it fetches it first.\n",
    "\n",
    "    Args:\n",
    "        video_url (str): The URL of the YouTube video from which the transcript is to be fetched.\n",
    "        user_question (str): The question posed by the user regarding the video.\n",
    "\n",
    "    Returns:\n",
    "        str: The answer to the user's question or a message indicating that the transcript \n",
    "             has not been fetched.\n",
    "    \"\"\"\n",
    "    global fetched_transcript, processed_transcript\n",
    "\n",
    "    # Check if the transcript needs to be fetched\n",
    "    if not processed_transcript:\n",
    "        if video_url:\n",
    "            # Fetch and preprocess transcript\n",
    "            fetched_transcript = get_transcript(video_url)\n",
    "            processed_transcript = process(fetched_transcript)\n",
    "        else:\n",
    "            return \"Please provide a valid YouTube URL.\"\n",
    "\n",
    "    if processed_transcript and user_question:\n",
    "        # Step 1: Chunk the transcript (only for Q&A)\n",
    "        chunks = chunk_transcript(processed_transcript)\n",
    "\n",
    "        # Step 2: Set up IBM Watson credentials\n",
    "        model_id, credentials, client, project_id = setup_credentials()\n",
    "\n",
    "        # Step 3: Initialize WatsonX LLM for Q&A\n",
    "        llm = initialize_watsonx_llm(model_id, credentials, project_id, define_parameters())\n",
    "\n",
    "        # Step 4: Create FAISS index for transcript chunks (only needed for Q&A)\n",
    "        embedding_model = setup_embedding_model(credentials, project_id)\n",
    "        faiss_index = create_faiss_index(chunks, embedding_model)\n",
    "\n",
    "        # Step 5: Set up the Q&A prompt and chain\n",
    "        qa_prompt = create_qa_prompt_template()\n",
    "        qa_chain = create_qa_chain(llm, qa_prompt)\n",
    "\n",
    "        # Step 6: Generate the answer using FAISS index\n",
    "        answer = generate_answer(user_question, faiss_index, qa_chain)\n",
    "        return answer\n",
    "    else:\n",
    "        return \"Please provide a valid question and ensure the transcript has been fetched.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216cb193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with gr.Blocks() as interface:\n",
    "    # Input field for YouTube URL\n",
    "    video_url = gr.Textbox(label=\"YouTube Video URL\", placeholder=\"Enter the YouTube Video URL\")\n",
    "    \n",
    "    # Outputs for summary and answer\n",
    "    summary_output = gr.Textbox(label=\"Video Summary\", lines=5)\n",
    "    question_input = gr.Textbox(label=\"Ask a Question About the Video\", placeholder=\"Ask your question\")\n",
    "    answer_output = gr.Textbox(label=\"Answer to Your Question\", lines=5)\n",
    "\n",
    "    # Buttons for selecting functionalities after fetching transcript\n",
    "    summarize_btn = gr.Button(\"Summarize Video\")\n",
    "    question_btn = gr.Button(\"Ask a Question\")\n",
    "\n",
    "    # Display status message for transcript fetch\n",
    "    transcript_status = gr.Textbox(label=\"Transcript Status\", interactive=False)\n",
    "\n",
    "    # Set up button actions\n",
    "    summarize_btn.click(summarize_video, inputs=video_url, outputs=summary_output)\n",
    "    question_btn.click(answer_question, inputs=[video_url, question_input], outputs=answer_output)\n",
    "\n",
    "# Launch the app with specified server name and port\n",
    "interface.launch(server_name=\"0.0.0.0\", server_port=7860)\n",
    "\n",
    "with gr.Blocks() as interface:\n",
    "    # Input field for YouTube URL\n",
    "    video_url = gr.Textbox(label=\"YouTube Video URL\", placeholder=\"Enter the YouTube Video URL\")\n",
    "    \n",
    "    # Outputs for summary and answer\n",
    "    summary_output = gr.Textbox(label=\"Video Summary\", lines=5)\n",
    "    question_input = gr.Textbox(label=\"Ask a Question About the Video\", placeholder=\"Ask your question\")\n",
    "    answer_output = gr.Textbox(label=\"Answer to Your Question\", lines=5)\n",
    "\n",
    "    # Buttons for selecting functionalities after fetching transcript\n",
    "    summarize_btn = gr.Button(\"Summarize Video\")\n",
    "    question_btn = gr.Button(\"Ask a Question\")\n",
    "\n",
    "    # Display status message for transcript fetch\n",
    "    transcript_status = gr.Textbox(label=\"Transcript Status\", interactive=False)\n",
    "\n",
    "    # Set up button actions\n",
    "    summarize_btn.click(summarize_video, inputs=video_url, outputs=summary_output)\n",
    "    question_btn.click(answer_question, inputs=[video_url, question_input], outputs=answer_output)\n",
    "\n",
    "# Launch the app with specified server name and port\n",
    "interface.launch(server_name=\"0.0.0.0\", server_port=7860)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
