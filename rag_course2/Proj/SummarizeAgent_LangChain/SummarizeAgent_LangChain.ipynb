{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d67d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ibm-watsonx-ai==0.2.6\n",
    "!pip install langchain==0.1.16\n",
    "!pip install langchain-ibm==0.1.4\n",
    "!pip install transformers==4.41.2\n",
    "!pip install huggingface-hub==0.23.4\n",
    "!pip install sentence-transformers==2.5.1\n",
    "!pip install chromadb\n",
    "!pip install wget==3.2\n",
    "!pip install --upgrade torch --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca059ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list | grep langchain\n",
    "!pip list | findstr langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a782e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use this section to suppress warnings generated by your code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import ModelTypes, DecodingMethods\n",
    "from ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'companyPolicies.txt'\n",
    "url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/6JDbUb_L3egv_eOkouY71A.txt'\n",
    "\n",
    "# Use wget to download the file\n",
    "wget.download(url, out=filename)\n",
    "print('file downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b21cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'r') as file:\n",
    "    # Read the contents of the file\n",
    "    contents = file.read()\n",
    "    print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564ed6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the document into chunks\n",
    "\n",
    "loader = TextLoader(filename)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff96c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding and storing\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "docsearch = Chroma.from_documents(texts, embeddings)  # store the embedding in docsearch using Chromadb\n",
    "print('document ingested')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b694d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\mohan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\mohan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\mohan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~andas (C:\\Users\\mohan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\mohan\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# RETRIEVAL\n",
    "# LLM model construction\n",
    "\n",
    "# ensure required packages are available\n",
    "%pip install -q langchain==0.1.16 openai\n",
    "\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "\n",
    "llm_model = \"nvidia/nemotron-nano-12b-v2-vl:free\"  # OpenRouter model\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model_name=llm_model,\n",
    "    openai_api_key=OPENROUTER_API_KEY,\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# llm_chat = LLMMathChain(llm=chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f533214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is mobile policy?',\n",
       " 'result': 'A **Mobile Phone Policy** is a set of guidelines established by an organization to regulate the use of mobile devices (e.g., smartphones, tablets) by employees. Its primary goals are to ensure **security**, **compliance with laws**, and **alignment with company values**. Below are the key components typically included in such a policy:\\n\\n---\\n\\n### **1. Purpose**  \\nTo promote responsible and secure use of mobile devices for both work and personal purposes, while protecting sensitive company and personal data.\\n\\n---\\n\\n### **2. Acceptable Use**  \\n- **Work-Related Tasks**: Devices should primarily be used for business activities.  \\n- **Limited Personal Use**: Employees may use devices for personal matters during non-work hours or breaks, provided it does not interfere with work obligations.  \\n- **Confidentiality**: Sensitive company data (e.g., trade secrets, customer information) must not leave the organization without authorization.\\n\\n---\\n\\n### **3. Security Requirements**  \\n- **Device Protection**: Employees must safeguard their devices with passwords, biometrics, or other security measures.  \\n- **Caution with Downloads/Links**: Avoid installing apps or clicking links from untrusted sources to prevent malware or breaches.  \\n- **Report Issues**: Promptly notify IT or supervisors of lost, stolen devices, or suspicious activity (e.g., unauthorized access).\\n\\n---\\n\\n### **4. Confidentiality**  \\n- **Secure Communication**: Avoid sharing sensitive information (e.g., company data, passwords) via unsecured platforms like public Wi-Fi, unencrypted emails, or social media.  \\n- **Privacy**: Employees should be discreet when discussing company matters in public spaces.\\n\\n---\\n\\n### **5. Compliance**  \\n- Adhere to laws such as **data protection regulations** (e.g., GDPR, CCPA) and **privacy laws** when handling personal or company data on devices.  \\n- Avoid transferring company data to non-compliant platforms or devices.\\n\\n---\\n\\n### **6. Lost or Stolen Devices**  \\n- **Immediate Reporting**: Employees must report lost or stolen devices to IT and management immediately.  \\n- **Remote Wipe**: If feasible, the company may remotely erase data from the device to prevent unauthorized access.\\n\\n---\\n\\n### **7. Consequences of Non-Compliance**  \\n- Disciplinary actions, including suspension, termination, or loss of device privileges, may follow policy violations.  \\n- Employees are responsible for reimbursing the company for recovery costs (e.g., data breach mitigation) caused by negligence.\\n\\n---\\n\\n### **8. Monitoring**  \\n- The organization reserves the right to monitor device usage to ensure compliance with the policy and address security risks.\\n\\n---\\n\\n### **Regular Updates**  \\nThe policy is reviewed periodically to address evolving technology, legal requirements, and security threats. Employees are expected to stay informed of updates.\\n\\n---\\n\\n**Key Takeaway**: This policy ensures mobile devices are used ethically, securely, and legally while balancing productivity and organizational protection. Employees are encouraged to seek clarification from IT or HR if unsure about device usage.\\n'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=chat, \n",
    "                                 chain_type=\"stuff\", \n",
    "                                 retriever=docsearch.as_retriever(), \n",
    "                                 return_source_documents=False)\n",
    "query = \"what is mobile policy?\"\n",
    "qa.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603c35fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=chat, \n",
    "                                 chain_type=\"stuff\", \n",
    "                                 retriever=docsearch.as_retriever(), \n",
    "                                 return_source_documents=False)\n",
    "query = \"Can you summarize the document for me?\"\n",
    "qa.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8635a52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a Prompt Template\n",
    "\n",
    "prompt_template = \"\"\"Use the information from the document to answer the question at the end. If you don't know the answer, just say that you don't know, definately do not try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a22c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=chat, \n",
    "                                 chain_type=\"stuff\", \n",
    "                                 retriever=docsearch.as_retriever(), \n",
    "                                 chain_type_kwargs=chain_type_kwargs, \n",
    "                                 return_source_documents=False)\n",
    "\n",
    "query = \"Can I eat in company vehicles?\"\n",
    "qa.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd1c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What I cannot do in it?\"\n",
    "qa.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3878c3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Conversation Memory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_message = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc0f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(llm=chat, \n",
    "                                           chain_type=\"stuff\", \n",
    "                                           retriever=docsearch.as_retriever(), \n",
    "                                           memory = memory, \n",
    "                                           get_chat_history=lambda h : h, \n",
    "                                           return_source_documents=False)\n",
    "\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is mobile policy?\"\n",
    "result = qa.invoke({\"question\":query}, {\"chat_history\": history})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa57f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.append((query, result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6fa824",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the aim of it?\"\n",
    "result = qa({\"question\": query}, {\"chat_history\": history})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6abec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap Up and Make an Agent\n",
    "\n",
    "def qa():\n",
    "    memory = ConversationBufferMemory(memory_key = \"chat_history\", return_message = True)\n",
    "    qa = ConversationalRetrievalChain.from_llm(llm=chat, \n",
    "                                               chain_type=\"stuff\", \n",
    "                                               retriever=docsearch.as_retriever(), \n",
    "                                               memory = memory, \n",
    "                                               get_chat_history=lambda h : h, \n",
    "                                               return_source_documents=False)\n",
    "    history = []\n",
    "    while True:\n",
    "        query = input(\"Question: \")\n",
    "        \n",
    "        if query.lower() in [\"quit\",\"exit\",\"bye\"]:\n",
    "            print(\"Answer: Goodbye!\")\n",
    "            break\n",
    "            \n",
    "        result = qa({\"question\": query}, {\"chat_history\": history})\n",
    "        \n",
    "        history.append((query, result[\"answer\"]))\n",
    "        \n",
    "        print(\"Answer: \", result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f19330",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
